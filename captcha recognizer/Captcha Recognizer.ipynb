{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from captcha.image import ImageCaptcha\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "alphabet = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "ALPHABET = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate captcha picture\n",
    "def random_captcha_text(char_set=number, captcha_size=4):\n",
    "    captcha_text = []\n",
    "    for i in range(captcha_size):\n",
    "        c = random.choice(char_set)\n",
    "        captcha_text.append(c)\n",
    "    return captcha_text\n",
    "\n",
    "def gen_captcha_text_and_image():\n",
    "    image = ImageCaptcha()\n",
    "    \n",
    "    captcha_text = random_captcha_text()\n",
    "    captcha_text = ''.join(captcha_text)\n",
    "    captcha = image.generate(captcha_text)\n",
    "    \n",
    "    captcha_image = Image.open(captcha)\n",
    "    captcha_image = np.array(captcha_image)\n",
    "    return captcha_text, captcha_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert colorful image to gray image\n",
    "def convert2gray(img):\n",
    "    if len(img.shape) > 2:\n",
    "        gray = np.mean(img, -1)\n",
    "        # above is a quick way to transform, but is an official way\n",
    "        # r, g, b = img[:,:,0], img[:,:,1], img[:,:,2]\n",
    "        # gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "        return gray\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def text2vec(text):\n",
    "    text_len = len(text)\n",
    "    if text_len > MAX_CAPTCHA:\n",
    "        raise ValueError('Captcha has maximum length as 4')\n",
    "\n",
    "    vector = np.zeros(MAX_CAPTCHA*CHAR_SET_LEN)\n",
    "    def char2pos(c):\n",
    "        if c =='_':\n",
    "            k = 62\n",
    "            return k\n",
    "        k = ord(c)-48\n",
    "        if k > 9:\n",
    "            k = ord(c) - 55\n",
    "            if k > 35:\n",
    "                k = ord(c) - 61\n",
    "                if k > 61:\n",
    "                    raise ValueError('No Map') \n",
    "        return k\n",
    "    for i, c in enumerate(text):\n",
    "        idx = i * CHAR_SET_LEN + char2pos(c)\n",
    "        vector[idx] = 1\n",
    "    return vector\n",
    "    \n",
    "\n",
    "def vec2text(vec):\n",
    "    char_pos = vec.nonzero()[0]\n",
    "    text=[]\n",
    "    for i, c in enumerate(char_pos):\n",
    "        char_at_pos = i #c/63\n",
    "        char_idx = c % CHAR_SET_LEN\n",
    "        if char_idx < 10:\n",
    "            char_code = char_idx + ord('0')\n",
    "        elif char_idx <36:\n",
    "            char_code = char_idx - 10 + ord('A')\n",
    "        elif char_idx < 62:\n",
    "            char_code = char_idx-  36 + ord('a')\n",
    "        elif char_idx == 62:\n",
    "            char_code = ord('_')\n",
    "        else:\n",
    "            raise ValueError('error')\n",
    "        text.append(chr(char_code))\n",
    "    return \"\".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_batch(batch_size = 128):\n",
    "    batch_x = np.zeros([batch_size, IMAGE_HEIGHT * IMAGE_WIDTH])\n",
    "    batch_y = np.zeros([batch_size, MAX_CAPTCHA * CHAR_SET_LEN])\n",
    "    \n",
    "    # in case sometimes the image size vary with (60, 160, 3)\n",
    "    def wrap_gen_captcha_text_and_image():\n",
    "        while True:\n",
    "            text, image = gen_captcha_text_and_image()\n",
    "            if image.shape == (60, 160, 3):\n",
    "                return text, image\n",
    "            \n",
    "    for i in range(batch_size):\n",
    "        text, image = wrap_gen_captcha_text_and_image()\n",
    "        image = convert2gray(image)\n",
    "        \n",
    "        batch_x[i, :] = image.flatten() / 255\n",
    "        batch_y[i, :] = text2vec(text)\n",
    "        \n",
    "    return batch_x, batch_y\n",
    "\n",
    "# define captcha nn skelton\n",
    "def crack_captcha_cnn(w_alpha=0.01, b_alpha=0.1):\n",
    "    x = tf.reshape(X, shape=[-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n",
    "    # 3 conv layer\n",
    "#     w_c1 = tf.Variable(w_alpha*tf.random_normal([3, 3, 1, 32]))\n",
    "#     b_c1 = tf.Variable(b_alpha*tf.random_normal([32]))\n",
    "#     conv1 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(x, w_c1, strides= [1, 1, 1, 1], padding = 'SAME'), b_c1))\n",
    "#     conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "#     conv1 = tf.nn.dropout(conv1, keep_prob)\n",
    "\n",
    "#     w_c2 = tf.Variable(w_alpha*tf.random_normal([3, 3, 32, 64]))\n",
    "#     b_c2 = tf.Variable(b_alpha*tf.random_normal([64]))\n",
    "#     conv2 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(x, w_c2, strides= [1, 1, 1, 1], padding = 'SAME'), b_c2))\n",
    "#     conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "#     conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    "    \n",
    "#     w_c3 = tf.Variable(w_alpha*tf.random_normal([3, 3, 64, 64]))\n",
    "#     b_c3 = tf.Variable(b_alpha*tf.random_normal([64]))\n",
    "#     conv3 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(x, w_c3, strides= [1, 1, 1, 1], padding = 'SAME'), b_c3))\n",
    "#     conv3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "#     conv3 = tf.nn.dropout(conv3, keep_prob)\n",
    "    w_c1 = tf.Variable(w_alpha*tf.random_normal([3, 3, 1, 32]))\n",
    "    b_c1 = tf.Variable(b_alpha*tf.random_normal([32]))\n",
    "    conv1 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(x, w_c1, strides=[1, 1, 1, 1], padding='SAME'), b_c1))\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    conv1 = tf.nn.dropout(conv1, keep_prob)\n",
    "\n",
    "    w_c2 = tf.Variable(w_alpha*tf.random_normal([3, 3, 32, 64]))\n",
    "    b_c2 = tf.Variable(b_alpha*tf.random_normal([64]))\n",
    "    conv2 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv1, w_c2, strides=[1, 1, 1, 1], padding='SAME'), b_c2))\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    "\n",
    "    w_c3 = tf.Variable(w_alpha*tf.random_normal([3, 3, 64, 64]))\n",
    "    b_c3 = tf.Variable(b_alpha*tf.random_normal([64]))\n",
    "    conv3 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv2, w_c3, strides=[1, 1, 1, 1], padding='SAME'), b_c3))\n",
    "    conv3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    conv3 = tf.nn.dropout(conv3, keep_prob)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    w_d = tf.Variable(w_alpha*tf.random_normal([8 * 20 * 64, 1024]))\n",
    "    b_d = tf.Variable(b_alpha*tf.random_normal([1024]))\n",
    "    dense = tf.reshape(conv3, [-1, w_d.get_shape().as_list()[0]])\n",
    "    dense = tf.nn.relu(tf.add(tf.matmul(dense, w_d), b_d))\n",
    "    dense = tf.nn.dropout(dense, keep_prob)\n",
    "    \n",
    "    w_out = tf.Variable(w_alpha*tf.random_normal([1024, MAX_CAPTCHA*CHAR_SET_LEN]))\n",
    "    b_out = tf.Variable(b_alpha*tf.random_normal([MAX_CAPTCHA*CHAR_SET_LEN]))\n",
    "    out = tf.add(tf.matmul(dense, w_out), b_out)\n",
    "    \n",
    "    return out\n",
    "\n",
    "# captcha recognizer nn structure\n",
    "def train_crack_captcha_cnn():\n",
    "    output    = crack_captcha_cnn()\n",
    "    loss    = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = output, labels = Y))\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "    predict   = tf.reshape(output, [-1, MAX_CAPTCHA, CHAR_SET_LEN])\n",
    "    max_idx_p = tf.argmax(predict, 2)\n",
    "    max_idx_l = tf.argmax(tf.reshape(Y, [-1, MAX_CAPTCHA, CHAR_SET_LEN]), 2)\n",
    "    correct_pred = tf.equal(max_idx_p, max_idx_l)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        step = 0\n",
    "        while True:\n",
    "            batch_x, batch_y = get_next_batch(64)\n",
    "            _, loss_ = sess.run([optimizer, loss], feed_dict={X: batch_x, Y: batch_y, keep_prob: 0.75})\n",
    "            print(step, loss_)\n",
    "            \n",
    "            # calculate accuracy every 100 step\n",
    "            if step % 100 == 0:\n",
    "                batch_x_test, batch_y_test = get_next_batch(100)\n",
    "                acc = sess.run(accuracy, feed_dict={X: batch_x_test, Y: batch_y_test, keep_prob: 0.75})\n",
    "                print(step, acc)\n",
    "            \n",
    "                # if accuray is greater than 50, store result and finish training\n",
    "                if acc > 0.85:\n",
    "                    saver.save(sess, \"./model/crack_captcha.model\", global_step=step)\n",
    "                    break\n",
    "            step += 1\n",
    "    \n",
    "\n",
    "def crack_captcha(captcha_image):\n",
    "    output = crack_captcha_cnn()\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "#         saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "#         saver.restore(sess, \"crack_capcha.model-4300\")\n",
    "        new_saver = tf.train.import_meta_graph('crack_capcha.model-4300.meta')\n",
    "        new_saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "        predict = tf.argmax(tf.reshape(output,[-1, MAX_CAPTCHA, CHAR_SET_LEN]), 2)\n",
    "        text_list = sess.run(predict, feed_dict={X: [captcha_image], keep_prob: 1})\n",
    "        text = text_list[0].tolist()\n",
    "        \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for crack_capcha.model-4300\n\t [[Node: save_6/RestoreV2_69 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_6/Const_0, save_6/RestoreV2_69/tensor_names, save_6/RestoreV2_69/shape_and_slices)]]\n\nCaused by op 'save_6/RestoreV2_69', defined at:\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-45-43c20ae74bb5>\", line 48, in <module>\n    predict_text = crack_captcha(image)\n  File \"<ipython-input-44-305babbec9a3>\", line 111, in crack_captcha\n    saver = tf.train.Saver()\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1051, in __init__\n    self.build()\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1081, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 675, in build\n    restore_sequentially, reshape)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 402, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 242, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 668, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for crack_capcha.model-4300\n\t [[Node: save_6/RestoreV2_69 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_6/Const_0, save_6/RestoreV2_69/tensor_names, save_6/RestoreV2_69/shape_and_slices)]]\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for crack_capcha.model-4300\n\t [[Node: save_6/RestoreV2_69 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_6/Const_0, save_6/RestoreV2_69/tensor_names, save_6/RestoreV2_69/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-43c20ae74bb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mkeep_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mpredict_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrack_captcha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"correct: () forcast: ()\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-305babbec9a3>\u001b[0m in \u001b[0;36mcrack_captcha\u001b[0;34m(captcha_image)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m#         saver.restore(sess, tf.train.latest_checkpoint('.'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"crack_capcha.model-4300\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_CAPTCHA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHAR_SET_LEN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1437\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1439\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for crack_capcha.model-4300\n\t [[Node: save_6/RestoreV2_69 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_6/Const_0, save_6/RestoreV2_69/tensor_names, save_6/RestoreV2_69/shape_and_slices)]]\n\nCaused by op 'save_6/RestoreV2_69', defined at:\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-45-43c20ae74bb5>\", line 48, in <module>\n    predict_text = crack_captcha(image)\n  File \"<ipython-input-44-305babbec9a3>\", line 111, in crack_captcha\n    saver = tf.train.Saver()\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1051, in __init__\n    self.build()\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1081, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 675, in build\n    restore_sequentially, reshape)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 402, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 242, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 668, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/zhengyangqiao/anaconda/envs/tensorflow3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for crack_capcha.model-4300\n\t [[Node: save_6/RestoreV2_69 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_6/Const_0, save_6/RestoreV2_69/tensor_names, save_6/RestoreV2_69/shape_and_slices)]]\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train = 1\n",
    "    if train == 0:\n",
    "        number = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "        text, image = gen_captcha_text_and_image()\n",
    "        print(\"Captcha size : \", image.shape)\n",
    "        \n",
    "        IMAGE_HEIGHT = 60\n",
    "        IMAGE_WIDTH = 160\n",
    "        MAX_CAPTCHA = len(text)\n",
    "        print(\"maximum captcha string: \", MAX_CAPTCHA)\n",
    "        \n",
    "        char_set = number\n",
    "        CHAR_SET_LEN = len(char_set)\n",
    "        \n",
    "        X = tf.placeholder(tf.float32, [None, IMAGE_HEIGHT * IMAGE_WIDTH])\n",
    "        Y = tf.placeholder(tf.float32, [None, MAX_CAPTCHA*CHAR_SET_LEN])\n",
    "        # dropout\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        train_crack_captcha_cnn()\n",
    "    if train == 1:\n",
    "        number = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "        IMAGE_HEIGHT = 60\n",
    "        IMAGE_WIDTH =  160\n",
    "        char_set = number\n",
    "        CHAR_SET_LEN = len(char_set)\n",
    "        text, image = gen_captcha_text_and_image()\n",
    "        \n",
    "#         f = plt.figure\n",
    "#         ax = f.subplot(111)\n",
    "#         ax.text(0.1, 0.9, text, ha='center', va='center', transform=ax.transAxes)\n",
    "#         plt.imshow(image)\n",
    "        \n",
    "#         plt.show()\n",
    "\n",
    "        f = plt.figure()\n",
    "        ax = f.add_subplot(111)\n",
    "        ax.text(0.1, 0.9,text, ha='center', va='center', transform=ax.transAxes)\n",
    "        \n",
    "        MAX_CAPTCHA = len(text)\n",
    "        image = convert2gray(image) / 255\n",
    "        \n",
    "        X = tf.placeholder(tf.float32, [None, IMAGE_HEIGHT * IMAGE_WIDTH])\n",
    "        Y = tf.placeholder(tf.float32, [None, MAX_CAPTCHA*CHAR_SET_LEN])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        predict_text = crack_captcha(image)\n",
    "        print(\"correct: () forcast: ()\".format(text, predict_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}